

## ðŸ“„ `ai_client.py` 

```python
## \file AIAssistant/ai_client.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ Google Gemini, Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð´ FreeCAD.
ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ð¼Ð¸ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ°Ð¼Ð¸.
"""

import asyncio
import time
from pathlib import Path
from typing import Optional, Dict, List, Any, Union
from io import IOBase
import google.generativeai as genai
from google.api_core.exceptions import (
    GatewayTimeout,
    RetryError,
    ServiceUnavailable,
    ResourceExhausted,
    InvalidArgument,
)
from google.auth.exceptions import (
    DefaultCredentialsError,
    RefreshError,
)
import FreeCAD

# === Ð›ÐžÐ“Ð“Ð•Ð  Ð”Ð›Ð¯ FREECAD ===
def log_info(msg: str) -> None:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ FreeCAD."""
    FreeCAD.Console.PrintMessage(f"[AIAssistant] {msg}\n")

def log_error(msg: str) -> None:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð¾ÑˆÐ¸Ð±ÐºÑƒ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ FreeCAD."""
    FreeCAD.Console.PrintError(f"[AIAssistant] ERROR: {msg}\n")

def log_warning(msg: str) -> None:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ FreeCAD."""
    FreeCAD.Console.PrintMessage(f"[AIAssistant] WARN: {msg}\n")

def log_debug(msg: str) -> None:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ FreeCAD."""
    FreeCAD.Console.PrintMessage(f"[AIAssistant] DEBUG: {msg}\n")

# --- ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ Ð´Ð»Ñ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð² Ð¸ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº ---
NETWORK_ERROR_MAX_ATTEMPTS = 5
SERVICE_UNAVAILABLE_MAX_ATTEMPTS = 3
INVALID_INPUT_MAX_ATTEMPTS = 3
INITIAL_RETRY_SLEEP_SECONDS = 2
NETWORK_RETRY_SLEEP_SECONDS = 120  # 2 Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹
SERVICE_RETRY_SLEEP_SECONDS_BASE = 10
QUOTA_EXHAUSTED_SLEEP_SECONDS = 14400  # 4 Ñ‡Ð°ÑÐ°

def normalize_answer(text: str) -> str:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Markdown-Ð¾Ð±Ñ‘Ñ€Ñ‚Ð¾Ðº Ð²Ñ€Ð¾Ð´Ðµ ```text ... ```."""
    text = text.strip()
    if text.startswith("```") and text.endswith("```"):
        lines = text.split("\n")
        if len(lines) >= 2:
            return "\n".join(lines[1:-1])
    if text.startswith("text\n"):
        text = text[5:]
    return text.strip()

def get_image_bytes(image_path: Path) -> Optional[bytes]:
    """Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ðº Ð±Ð°Ð¹Ñ‚Ñ‹."""
    try:
        with open(image_path, "rb") as f:
            return f.read()
    except Exception as ex:
        log_error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð±Ð°Ð¹Ñ‚Ñ‹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°: {image_path}")
        return None

class GoogleGenerativeAi:
    """
    ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Google Generative AI.
    ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð² FreeCAD Ð±ÐµÐ· Ð²Ð½ÐµÑˆÐ½Ð¸Ñ… Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹.
    """

    def __init__(
        self,
        api_key: str,
        model_name: str = "gemini-2.5-flash",
        generation_config: Optional[Dict] = None,
        system_instruction: Optional[str] = None,
    ):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ ÐºÐ»Ð°ÑÑÐ° GoogleGenerativeAi.

        Args:
            api_key (str): ÐšÐ»ÑŽÑ‡ API Ð´Ð»Ñ Google Generative AI.
            model_name (str): Ð˜Ð¼Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Gemini Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ.
            generation_config (Dict, optional): ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸.
            system_instruction (Optional[str], optional): Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸.
        """
        self.api_key = api_key
        self.model_name = model_name
        self.generation_config = generation_config if generation_config is not None else {'response_mime_type': 'text/plain'}
        self.system_instruction = system_instruction

        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config,
                system_instruction=self.system_instruction,
            )
            log_info(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model.model_name} Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð°")
        except (DefaultCredentialsError, RefreshError) as ex:
            log_error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Gemini API")
            raise
        except Exception as ex:
            log_error("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Gemini")
            raise

    def ask(self, q: str, attempts: int = 15, save_dialogue: bool = False,
            clean_response: bool = True, context: Optional[Union[str, List[str]]] = None) -> Optional[str]:
        """
        ÐœÐµÑ‚Ð¾Ð´ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚.

        Args:
            q (str): Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸.
            attempts (int): ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°.
            save_dialogue (bool): Ð¤Ð»Ð°Ð³ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° (Ð½Ðµ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½ Ð² FreeCAD).
            clean_response (bool): Ð¤Ð»Ð°Ð³ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸ ÐºÐ¾Ð´Ð°.
            context (Optional[Union[str, List[str]]]): Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸.

        Returns:
            Optional[str]: Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð»Ð¸ `None` Ð² ÑÐ»ÑƒÑ‡Ð°Ðµ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð¸.
        """
        content_to_send: List[Any] = []
        if context:
            context_str = "\n".join(context) if isinstance(context, list) else context
            content_to_send.append(f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context_str}\n")
            log_debug(f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ RAG Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ Ð² Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð´Ð»Ð¸Ð½Ð°: {len(context_str)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²).")
        content_to_send.append(q)

        for attempt in range(attempts):
            try:
                response = self.model.generate_content(content_to_send)
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                    return normalize_answer(response_text) if clean_response else response_text
                else:
                    sleep_time = INITIAL_RETRY_SLEEP_SECONDS ** attempt
                    log_debug(f"ÐžÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ð¾Ñ‚Ð²ÐµÑ‚. ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ°: {attempt + 1}/{attempts}. ÐŸÐ°ÑƒÐ·Ð°: {sleep_time} ÑÐµÐº.")
                    time.sleep(sleep_time)
                    continue
            except ResourceExhausted:
                log_error("Ð˜ÑÑ‡ÐµÑ€Ð¿Ð°Ð½ Ð»Ð¸Ð¼Ð¸Ñ‚ ÐºÐ²Ð¾Ñ‚Ñ‹.")
                return "ResourceExhausted"
            except (DefaultCredentialsError, RefreshError):
                log_error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸.")
                return None
            except (GatewayTimeout, ServiceUnavailable):
                if attempt >= SERVICE_UNAVAILABLE_MAX_ATTEMPTS:
                    log_error(f"Ð¡ÐµÑ€Ð²Ð¸Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ Ð¿Ð¾ÑÐ»Ðµ {SERVICE_UNAVAILABLE_MAX_ATTEMPTS} Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº.")
                    break
                sleep_time_service = INITIAL_RETRY_SLEEP_SECONDS**attempt + SERVICE_RETRY_SLEEP_SECONDS_BASE
                log_error(f"Ð¡ÐµÑ€Ð²Ð¸Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ°: {attempt + 1}/{attempts}. ÐŸÐ°ÑƒÐ·Ð°: {sleep_time_service} ÑÐµÐº.")
                time.sleep(sleep_time_service)
                continue
            except (ValueError, TypeError):
                if attempt >= INVALID_INPUT_MAX_ATTEMPTS:
                    log_error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ÑÐ»Ðµ {INVALID_INPUT_MAX_ATTEMPTS} Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº.")
                    break
                time.sleep(5)
                continue
            except Exception as ex:
                log_error("ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°.")
                return None

        log_error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ÑÐ»Ðµ {attempts} Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº.")
        return None

    def describe_image(
        self, image: Path | bytes, mime_type: Optional[str] = 'image/jpeg', prompt: Optional[str] = ''
    ) -> Optional[str]:
        """
        Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² Ð¼Ð¾Ð´ÐµÐ»ÑŒ Gemini Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐµÐ³Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ.

        Args:
            image (Path | bytes): ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð»Ð¸ Ð±Ð°Ð¹Ñ‚Ñ‹.
            mime_type (Optional[str]): MIME-Ñ‚Ð¸Ð¿ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.
            prompt (Optional[str]): Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸.

        Returns:
            Optional[str]: Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð»Ð¸ `None` Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ.
        """
        image_data: bytes
        if isinstance(image, Path):
            img_bytes = get_image_bytes(image)
            if img_bytes is None:
                return None
            image_data = img_bytes
        elif isinstance(image, bytes):
            image_data = image
        else:
            log_error(f"ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ð´Ð»Ñ 'image'. ÐžÐ¶Ð¸Ð´Ð°ÐµÑ‚ÑÑ Path Ð¸Ð»Ð¸ bytes, Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾: {type(image)}")
            return None

        content_parts: List[Any] = []
        if prompt:
            content_parts.append(prompt)
        content_parts.append(image_data)

        try:
            response = self.model.generate_content(content_parts)
            if hasattr(response, 'text') and response.text:
                return response.text
            else:
                log_info(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð²ÐµÑ€Ð½ÑƒÐ»Ð° Ð¾Ñ‚Ð²ÐµÑ‚ Ð±ÐµÐ· Ñ‚ÐµÐºÑÑ‚Ð°: {response}")
                return None
        except Exception as ex:
            log_error("ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.")
            return None
```



Ð­Ñ‚Ð¾Ñ‚ Ñ„Ð°Ð¹Ð» **Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ** Ð² Ð°Ð´Ð´Ð¾Ð½Ðµ `AIAssistant` Ð´Ð»Ñ FreeCAD Ð¸ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð°Ñˆ Ð¼Ð¾Ñ‰Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ð½ÐµÐºÑ‚Ð¾Ñ€ Ðº Google Gemini.

```mermaid
flowchart TD
    A[Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ GoogleGenerativeAi] --> B{"Ð£ÑÐ¿ÐµÑˆÐ½Ð° Ð»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° API?"}
    B -- "ÐÐµÑ‚" --> C["Ð’Ñ‹Ð±Ñ€Ð¾Ñ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¸Ð»Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸"]
    B -- "Ð”Ð°" --> D["ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð°. Ð¡Ð¾Ð·Ð´Ð°Ð½ ÑÐµÐ°Ð½Ñ Ñ‡Ð°Ñ‚Ð° _chat"]

    D --> E{"ÐšÐ°ÐºÐ¾Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð²Ñ‹Ð·Ð²Ð°Ð½?"}

    E -->|"ask stateless"| F["Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ content_to_send Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ RAG"]
    F --> G["Ð¦Ð¸ÐºÐ» Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº: Ð´Ð¾ attempts"]
    G --> H{"ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½?"}
    H -- "ÐÐµÑ‚" --> I{"Ð¢Ð¸Ð¿ Ð¾ÑˆÐ¸Ð±ÐºÐ¸?"}

    I -->|"Ð¡ÐµÑ‚ÐµÐ²Ð°Ñ / ServiceUnavailable"| J["ÐŸÐ°ÑƒÐ·Ð° + Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€"]
    I -->|"ResourceExhausted"| K["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ 'ResourceExhausted'"]
    I -->|"InvalidArgument / Auth"| L["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ None"]
    H -- "Ð”Ð°" --> M{"ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¾Ñ‚Ð²ÐµÑ‚Ð°?"}
    M -- "Ð”Ð°" --> N["ÐŸÑ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ normalize_answer"]
    M -- "ÐÐµÑ‚" --> O["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ ÑÑ‹Ñ€Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"]
    N --> P["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð°"]
    O --> P

    E -->|"chat stateful"| Q["Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ parts_to_send Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ RAG"]
    Q --> R["ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· _chat.send_message_async"]
    R --> S{"Ð£ÑÐ¿ÐµÑˆÐµÐ½ Ð»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚?"}
    S -- "ÐÐµÑ‚" --> T{"Ð¢Ð¸Ð¿ Ð¾ÑˆÐ¸Ð±ÐºÐ¸?"}
    T -->|"ResourceExhausted"| U["Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ð°ÑƒÐ·Ð° + Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº Ñ‡Ð°Ñ‚Ð°"]
    T -->|"ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¸Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²"| V["ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ + Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€"]
    T -->|"gRPC DEADLINE_EXCEEDED"| W["ÐŸÐ°ÑƒÐ·Ð° + Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº Ñ‡Ð°Ñ‚Ð°"]
    S -- "Ð”Ð°" --> X["Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð² chat_history: Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ â†’ Ð¼Ð¾Ð´ÐµÐ»ÑŒ"]
    X --> Y["ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² JSON"]
    Y --> Z["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð°"]

    E -->|"describe_image"| AA["Ð§Ñ‚ÐµÐ½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: Path â†’ bytes"]
    AA --> AB{"Ð£ÑÐ¿ÐµÑˆÐ½Ð¾?"}
    AB -- "ÐÐµÑ‚" --> AC["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ None"]
    AB -- "Ð”Ð°" --> AD["Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ„Ð°Ð¹Ð»Ð° Ñ‡ÐµÑ€ÐµÐ· genai.upload_file_async"]
    AD --> AE["ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° [prompt + file] Ð² generate_content"]
    AE --> AF{"ÐžÑ‚Ð²ÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‚ÐµÐºÑÑ‚?"}
    AF -- "ÐÐµÑ‚" --> AG["Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ feedback, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚ None"]
    AF -- "Ð”Ð°" --> AH["Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ"]

    C --> AI["Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ"]
    P --> AI
    L --> AI
    K --> AI
    Z --> AI
    U --> AI
    V --> AI
    W --> AI
    AG --> AI
    AH --> AI

    ```