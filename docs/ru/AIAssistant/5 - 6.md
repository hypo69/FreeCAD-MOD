# üìò –£—á–µ–±–Ω—ã–π –∫—É—Ä—Å: –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–¥–æ–Ω–æ–≤ –¥–ª—è FreeCAD  
## –ß–∞—Å—Ç—å 5‚Äì6: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ò–ò (Ollama, OpenAI, Google Gemini)

> **–¶–µ–ª—å**: –Ω–∞—É—á–∏—Ç—å –∞–¥–¥–æ–Ω `AIAssistant` –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å **—Å–≤—è–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç** (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + —Ç–µ–∫—Å—Ç) –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –∏ –ø–æ–ª—É—á–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ FreeCAD.

---

## üìå –û–±–∑–æ—Ä –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —ç—Ç–æ–π —á–∞—Å—Ç–∏ –∞–¥–¥–æ–Ω –±—É–¥–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å:
- **–õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏**: Ollama (Llava, Llama3 –∏ –¥—Ä.)
- **–û–±–ª–∞—á–Ω—ã–µ API**: OpenAI (GPT-4o)
- **Google Gemini**: —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ `genai.upload_file`
- **–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å**: –≤—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–∫–∏–¥–∞—é—Ç –≤–∞—à—É –º–∞—à–∏–Ω—É (–µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±–ª–∞—á–Ω—ã–π API)

---

## üìÅ –û–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–¥–¥–æ–Ω–∞

```
AIAssistant/
‚îú‚îÄ‚îÄ Resources/
‚îÇ   ‚îî‚îÄ‚îÄ icons/
‚îÇ       ‚îú‚îÄ‚îÄ ai_assistant.svg
‚îÇ       ‚îú‚îÄ‚îÄ load_image.svg
‚îÇ       ‚îú‚îÄ‚îÄ load_text.svg
‚îÇ       ‚îú‚îÄ‚îÄ link_content.svg
‚îÇ       ‚îú‚îÄ‚îÄ manage_content.svg
‚îÇ       ‚îî‚îÄ‚îÄ ai_chat.svg          ‚Üê –Ω–æ–≤–∞—è –∏–∫–æ–Ω–∫–∞
‚îú‚îÄ‚îÄ InitGui.py
‚îú‚îÄ‚îÄ ai_assistant_workbench.py    ‚Üê –æ–±–Ω–æ–≤–ª—ë–Ω
‚îú‚îÄ‚îÄ project_manager.py
‚îú‚îÄ‚îÄ settings_dialog.py           ‚Üê —Ä–∞—Å—à–∏—Ä–µ–Ω
‚îú‚îÄ‚îÄ ai_client.py                 ‚Üê —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
‚îî‚îÄ‚îÄ data/
```

---

## üìÑ 1. `ai_client.py` ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –ò–ò

–≠—Ç–æ—Ç —Ñ–∞–π–ª **–∑–∞–º–µ–Ω—è–µ—Ç** –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∏–µ–Ω—Ç –∏–∑ –ß–∞—Å—Ç–∏ 5 –∏ **–∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤–∞—à `GoogleGenerativeAi`**.

```python
## \file AIAssistant/ai_client.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏: Ollama, OpenAI, Google Gemini.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
"""

import os
import json
import base64
import requests
import asyncio
from pathlib import Path
from typing import Optional, Dict, Any
import FreeCAD

# === –õ–û–ì–ì–ï–† –î–õ–Ø FREECAD ===
def log_info(msg: str) -> None:
    """–§—É–Ω–∫—Ü–∏—è –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å FreeCAD."""
    FreeCAD.Console.PrintMessage(f"[AIAssistant] {msg}\n")

def log_error(msg: str) -> None:
    """–§—É–Ω–∫—Ü–∏—è –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å FreeCAD."""
    FreeCAD.Console.PrintError(f"[AIAssistant] ERROR: {msg}\n")

# === –ö–õ–ò–ï–ù–¢–´ –ü–†–û–í–ê–ô–î–ï–†–û–í ===
class OllamaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Ollama API."""

    def __init__(self, model: str = "llava:latest", base_url: str = "http://localhost:11434"):
        """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama."""
        self.model = model
        self.base_url = base_url

    def encode_image(self, image_path: str) -> str:
        """–§—É–Ω–∫—Ü–∏—è –∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64."""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    def ask(self, prompt: str, image_path: Optional[str] = None) -> str:
        """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Ollama –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
        url: str = f"{self.base_url}/api/generate"
        payload: Dict[str, Any] = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        if image_path and Path(image_path).suffix.lower() in {'.png', '.jpg', '.jpeg'}:
            payload["images"] = [self.encode_image(image_path)]

        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json().get("response", "No response")
        except Exception as ex:
            return f"Ollama error: {str(ex)}"


class OpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI API."""

    def __init__(self, api_key: str, model: str = "gpt-4o"):
        """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI."""
        self.api_key = api_key
        self.model = model

    def encode_image(self, image_path: str) -> str:
        """–§—É–Ω–∫—Ü–∏—è –∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64."""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    def ask(self, prompt: str, image_path: Optional[str] = None) -> str:
        """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
        if not self.api_key:
            return "OpenAI error: API key not set."

        url: str = "https://api.openai.com/v1/chat/completions"
        headers: Dict[str, str] = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        messages = [{"role": "user", "content": [{"type": "text", "text": prompt}]}]
        if image_path and Path(image_path).suffix.lower() in {'.png', '.jpg', '.jpeg'}:
            b64_img = self.encode_image(image_path)
            messages[0]["content"].append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}
            })

        payload: Dict[str, Any] = {"model": self.model, "messages": messages, "max_tokens": 1000}
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
        except Exception as ex:
            return f"OpenAI error: {str(ex)}"


class GeminiClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è Google Gemini API (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–∑ gemini.py)."""

    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash-latest"):
        """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç Google Generative AI."""
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name=model_name)
            log_info(f"Gemini model '{model_name}' initialized")
        except Exception as ex:
            log_error(f"Failed to initialize Gemini: {str(ex)}")
            raise

    def ask(self, prompt: str, image_path: Optional[str] = None) -> Optional[str]:
        """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Gemini –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
        import google.generativeai as genai
        content = []
        if image_path and Path(image_path).exists():
            try:
                uploaded_file = genai.upload_file(image_path)
                content = [uploaded_file, prompt]
                log_info(f"Image {image_path} uploaded to Gemini")
            except Exception as ex:
                log_error(f"Image upload failed: {str(ex)}")
                content = [prompt]
        else:
            content = [prompt]

        try:
            response = self.model.generate_content(content)
            if hasattr(response, 'text') and response.text:
                return response.text.strip()
            else:
                log_error("Empty response from Gemini")
                return None
        except Exception as ex:
            return f"Gemini error: {str(ex)}"


# === –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ö–õ–ò–ï–ù–¢ ===
class AIClient:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""

    def __init__(self):
        """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ QSettings."""
        from PySide import QtCore
        settings = QtCore.QSettings("FreeCAD", "AIAssistant")
        self.provider = settings.value("provider", "gemini")
        self.model = settings.value("model", "gemini-1.5-flash-latest")
        self.api_key = settings.value("api_key", "")
        self.base_url = settings.value("base_url", "http://localhost:11434")

    def ask(self, prompt: str, image_path: Optional[str] = None) -> str:
        """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—É."""
        if self.provider == "ollama":
            client = OllamaClient(model=self.model, base_url=self.base_url)
            return client.ask(prompt, image_path)
        elif self.provider == "openai":
            client = OpenAIClient(api_key=self.api_key, model=self.model)
            return client.ask(prompt, image_path)
        elif self.provider == "gemini":
            try:
                client = GeminiClient(api_key=self.api_key, model_name=self.model)
                response = client.ask(prompt, image_path)
                return response if response is not None else "Gemini returned empty response."
            except Exception as ex:
                return f"Gemini error: {str(ex)}"
        else:
            return f"Provider '{self.provider}' is not supported."
```

---

## üìÑ 2. –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π `settings_dialog.py`

```python
## \file AIAssistant/settings_dialog.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
–î–∏–∞–ª–æ–≥ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏, –≤–≤–æ–¥ API-–∫–ª—é—á–∞.
"""

from PySide import QtGui, QtCore

class SettingsDialog(QtGui.QDialog):
    """–î–∏–∞–ª–æ–≥ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ò–ò."""

    def __init__(self):
        """–§—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–∞—Å—Ç—Ä–æ–µ–∫."""
        super().__init__()
        self.setWindowTitle("AI Assistant Settings")
        self.resize(500, 350)

        settings = QtCore.QSettings("FreeCAD", "AIAssistant")
        self.provider = settings.value("provider", "gemini")
        self.model = settings.value("model", "gemini-1.5-flash-latest")
        self.api_key = settings.value("api_key", "")
        self.base_url = settings.value("base_url", "http://localhost:11434")

        self.provider_combo = QtGui.QComboBox()
        self.provider_combo.addItems(["gemini", "ollama", "openai"])
        self.provider_combo.setCurrentText(self.provider)
        self.provider_combo.currentTextChanged.connect(self.on_provider_changed)

        self.model_input = QtGui.QLineEdit(self.model)
        self.api_key_input = QtGui.QLineEdit(self.api_key)
        self.api_key_input.setEchoMode(QtGui.QLineEdit.Password)
        self.base_url_input = QtGui.QLineEdit(self.base_url)

        self.on_provider_changed(self.provider)

        layout = QtGui.QFormLayout()
        layout.addRow("AI Provider:", self.provider_combo)
        layout.addRow("Model:", self.model_input)
        layout.addRow("API Key:", self.api_key_input)
        layout.addRow("Base URL (Ollama):", self.base_url_input)

        btn_layout = QtGui.QHBoxLayout()
        save_btn = QtGui.QPushButton("Save")
        cancel_btn = QtGui.QPushButton("Cancel")
        save_btn.clicked.connect(self.save_settings)
        cancel_btn.clicked.connect(self.reject)
        btn_layout.addWidget(save_btn)
        btn_layout.addWidget(cancel_btn)

        main_layout = QtGui.QVBoxLayout()
        main_layout.addLayout(layout)
        main_layout.addLayout(btn_layout)
        self.setLayout(main_layout)

    def on_provider_changed(self, provider: str) -> None:
        """–§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–æ–ª–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        if provider == "gemini":
            self.base_url_input.setEnabled(False)
            self.api_key_input.setEnabled(True)
            self.model_input.setText("gemini-1.5-flash-latest")
        elif provider == "openai":
            self.base_url_input.setEnabled(False)
            self.api_key_input.setEnabled(True)
        else:  # ollama
            self.base_url_input.setEnabled(True)
            self.api_key_input.setEnabled(False)

    def save_settings(self) -> None:
        """–§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ QSettings."""
        settings = QtCore.QSettings("FreeCAD", "AIAssistant")
        settings.setValue("provider", self.provider_combo.currentText())
        settings.setValue("model", self.model_input.text())
        settings.setValue("api_key", self.api_key_input.text())
        settings.setValue("base_url", self.base_url_input.text())
        QtGui.QMessageBox.information(self, "Saved", "Settings saved successfully!")
        self.accept()
```

---

## üìÑ 3. –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π `ai_assistant_workbench.py` (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)

–í –º–µ—Ç–æ–¥–µ `AskAICommand.Activated`:

```python
def Activated(self) -> None:
    """–§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä."""
    if project is None or not project.get_all_links():
        QtGui.QMessageBox.information(None, "No Data", "First link an image to a text using 'Link Content'.")
        return

    links = project.get_all_links()
    image_file, text_file = next(iter(links.items()))
    image_path: Path = AI_DATA_DIR / image_file
    text_path: Path = AI_DATA_DIR / text_file

    if not text_path.exists():
        QtGui.QMessageBox.critical(None, "Error", f"Text file not found: {text_path}")
        return

    try:
        with open(text_path, 'r', encoding='utf-8') as f:
            prompt: str = f.read()
    except Exception as ex:
        QtGui.QMessageBox.critical(None, "Error", f"Cannot read text file:\n{str(ex)}")
        return

    FreeCAD.Console.PrintMessage("[AIAssistant] Sending to AI...\n")
    try:
        from AIAssistant.ai_client import AIClient
        client = AIClient()
        response: str = client.ask(prompt, str(image_path))
    except Exception as ex:
        response = f"AI client error: {str(ex)}"

    save_ai_response_to_history(prompt, response)
    dialog = AIResponseDialog(prompt, response)
    dialog.exec_()
```

---

## üîë –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ

| –ü—Ä–æ–≤–∞–π–¥–µ—Ä | –£—Å—Ç–∞–Ω–æ–≤–∫–∞ | –ú–æ–¥–µ–ª—å |
|----------|----------|--------|
| **Ollama** | `ollama pull llava` | `llava:latest` |
| **OpenAI** | API-–∫–ª—é—á —Å [platform.openai.com](https://platform.openai.com/) | `gpt-4o` |
| **Gemini** | API-–∫–ª—é—á —Å [ai.google.dev](https://ai.google.dev/) | `gemini-1.5-flash-latest` |

---

## ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

- **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å**: –∫–∞–∂–¥—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å
- **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å**: –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å Claude, LM Studio –∏ –¥—Ä.
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: API-–∫–ª—é—á–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –∑–∞—â–∏—â—ë–Ω–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –û–° (`QSettings`)
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ standalone –∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏—è—Ö FreeCAD

---

## ‚ñ∂Ô∏è –ß—Ç–æ –¥–∞–ª—å—à–µ?

–í **–ß–∞—Å—Ç–∏ 7** –º—ã:
- –†–µ–∞–ª–∏–∑—É–µ–º **—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä** –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D-–æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –ò–ò
- –î–æ–±–∞–≤–∏–º **—à–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤** (¬´–æ–ø–∏—à–∏ –¥–ª—è 3D-–ø–µ—á–∞—Ç–∏¬ª, ¬´–ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è¬ª)
- –í–Ω–µ–¥—Ä–∏–º **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —ç—Å–∫–∏–∑–æ–≤** —á–µ—Ä–µ–∑ Draft/PartDesign

