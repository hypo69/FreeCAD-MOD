## \file /src/utils/string/ai_string_utils.py
# -*- coding: utf-8 -*-
#! .pyenv/bin/python3


"""
Утилиты для приведения строк к требованиям обучения и нормализации ответов от языковых моделей.
================================================================================================

**Назначение**

Этот модуль предоставляет функции для обработки и очистки строк, включая:
1.  Подготовку текстовых данных для обучающих наборов (экранирование кавычек, удаление лишних пробелов,
    удаление/замена символов новой строки, табуляции и т.п.).
2.  Нормализацию ответов от языковых моделей (удаление обрамляющих блоков кода).

.. module:: src.utils.string.ai_string_utils  # Пример нового пути модуля
"""

import re
from typing import Union, List

# =========================================================================================
# Функции для подготовки данных для обучения (из string_for_train.py)
# =========================================================================================

def string_for_train(data: Union[str, List[str]]) -> str:
    """
    Очищает и форматирует данные для обучения.

    Экранирует двойные кавычки (`"`) символом обратной косой черты (`\\`).
    Заменяет все последовательности пробельных символов (включая пробелы,
    табуляцию `\\t`, переводы строки `\\n`, `\\r`, `\\f`, `\\v`) одним пробелом.
    Удаляет начальные и конечные пробелы.

    Args:
        data (Union[str, List[str]]): Входные данные. Могут быть строкой или
                                      списком строк.

    Returns:
        str: Очищенная и объединенная строка (если на входе был список),
             готовая для использования в обучении. Возвращает пустую строку,
             если тип входных данных не строка и не список строк.

    Examples:
        >>> string_for_train('   Это  строка   с "кавычками"\\nи\\tпробелами. ')
        'Это строка с \\"кавычками\\" и пробелами.'
        >>> string_for_train(['Первая строка.', '   Вторая "строка"\\tс\\nпробелами.'])
        'Первая строка. Вторая \\"строка\\" с пробелами.'
        >>> string_for_train('Строка\nс\nпереносами\n')
        'Строка с переносами'
        >>> string_for_train(None)
        ''
        >>> string_for_train(123)
        ''
    """
    cleaned_text: str = ""

    if isinstance(data, str):
        # Экранирование кавычек
        cleaned_text = data.replace('"', '\\"')
        # Замена всех последовательностей пробельных символов (\s включает \n, \t, \r, \f, \v и пробел)
        # одним пробелом и обрезка краев
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text
    elif isinstance(data, list):
        # Обработка каждого элемента списка
        processed_items = []
        for item in data:
            if isinstance(item, str):
                # Экранирование кавычек
                cleaned_item = item.replace('"', '\\"')
                # НЕ удаляем \n, \t и т.д. здесь отдельно,
                # т.к. финальный re.sub обработает всю строку целиком
                processed_items.append(cleaned_item)
            else:
                # Пропустить нестроковые элементы или обработать иначе?
                # В текущей реализации они будут проигнорированы при объединении,
                # но можно добавить логирование или обработку ошибок.
                pass # Явное указывание на, что ничего не делаем
        # Объединение элементов списка в одну строку через пробел
        # Пробел между элементами важен, чтобы re.sub корректно их разделил
        full_text = ' '.join(processed_items)
        # Финальное удаление повторяющихся и нежелательных пробельных символов (\n, \t и др.),
        # замена их одним пробелом и обрезка краев всей строки
        cleaned_text = re.sub(r'\s+', ' ', full_text).strip()
        return cleaned_text
    else:
        # Возврат пустой строки для некорректного типа данных
        return ""

# =========================================================================================
# Функции для нормализации ответов ИИ (из ai_response_normalizer.py)
# =========================================================================================

# Список префиксов и суффиксов, обозначающих блоки кода в ответах моделей
_NORMALIZER_PREFIXES: list[str] = [
    '```md\n',
    '```md ', # Добавим вариант с пробелом
    '```md',
    '```markdown\n',
    '```markdown ', # Добавим вариант с пробелом
    '```markdown',
    '```html\n',
    '```html ', # Добавим вариант с пробелом
    '```html',
    '```json\n', # Добавим другие возможные типы
    '```json ',
    '```json',
    '```python\n',
    '```python ',
    '```python',
    '```text\n',
    '```text ',
    '```text',
    '```\n',
    '``` ',
    '```',
]
_NORMALIZER_SUFFIX: str = '```'


def normalize_answer(text: str) -> str:
    """
    Нормализует текстовый ответ, удаляя обрамляющие блоки кода markdown.

    Проверяет, начинается ли строка `text` одним из префиксов из списка
    `_NORMALIZER_PREFIXES` (например, '```html\\n', '```markdown', '```')
    и заканчивается ли она суффиксом `_NORMALIZER_SUFFIX` ('```').
    Если оба условия выполняются, удаляет соответствующий префикс и суффикс.
    В противном случае возвращает исходную строку без изменений.

    Args:
        text (str): Исходная строка текста, потенциально содержащая
                    обрамляющие блоки кода.

    Returns:
        str: Нормализованная строка без начального и конечного блоков кода,
             либо исходная строка, если блоки не найдены.

    Examples:
        >>> normalize_answer("```html\\n<p>Пример</p>\\n```")
        '<p>Пример</p>\\n'
        >>> normalize_answer("```markdown\n# Заголовок\nТекст.\n```")
        '# Заголовок\\nТекст.\\n'
        >>> normalize_answer("```\nПросто текст\n```")
        'Просто текст\\n'
        >>> normalize_answer("Обычный текст без блоков.")
        'Обычный текст без блоков.'
        >>> normalize_answer("```Неполный блок")
        '```Неполный блок'
        >>> normalize_answer("Блок в конце```")
        'Блок в конце```'
        >>> normalize_answer("```md Текст```") # Пример с пробелом после md
        'Текст'
    """
    if not isinstance(text, str):
        # Можно добавить обработку ошибок или вернуть пустую строку/None
        return "" # Или return text, если нужно пропустить не-строки

    normalized_text = text # Начинаем с исходного текста

    for prefix in _NORMALIZER_PREFIXES:
        # Проверка наличие префикса И суффикса
        if normalized_text.startswith(prefix) and normalized_text.endswith(_NORMALIZER_SUFFIX):
            # Удаляем префикс
            normalized_text = normalized_text.removeprefix(prefix)
            # Удаляем суффикс
            normalized_text = normalized_text.removesuffix(_NORMALIZER_SUFFIX)
            # Так как нашли и удалили, можно выходить из цикла
            break # Важно: прекращаем поиск после первого совпадения

    # Можно добавить .strip() для удаления случайных пробелов по краям после удаления блоков
    # return normalized_text.strip()
    # Однако, это может быть нежелательно, если внутри блока важны отступы
    return normalized_text

# =========================================================================================
# Пример использования (можно закомментировать или удалить)
# =========================================================================================
if __name__ == '__main__':
    # Примеры для string_for_train
    print("--- string_for_train ---")
    test_str = '   Это  строка   с "кавычками"   и    пробелами. '
    print(f"Original: '{test_str}'")
    print(f"Cleaned:  '{string_for_train(test_str)}'")

    # Добавлен тест с \n и \t
    test_str_ws = '   Строка\tс \n новой строкой\n\nи\t табами.  "кавычка" '
    print(f"Original WS: '{test_str_ws}'")
    print(f"Cleaned WS:  '{string_for_train(test_str_ws)}'")


    test_list = ['Первая строка.', '   Вторая "строка"   с пробелами.', ' Третья    ', '   ']
    print(f"Original list: {test_list}")
    print(f"Cleaned list: '{string_for_train(test_list)}'")

    # Добавлен тест списка с \n и \t
    test_list_ws = ['Первая\nстрока.', ' \tВторая "строка"\t\tс\nпробелами.']
    print(f"Original list WS: {test_list_ws}")
    print(f"Cleaned list WS: '{string_for_train(test_list_ws)}'")


    print(f"Invalid input (int): '{string_for_train(123)}'")
    print(f"Invalid input (None): '{string_for_train(None)}'")


    # Примеры для normalize_answer
    print("\n--- normalize_answer ---")
    tests_norm = [
        "```html\n<p>Пример</p>\n```",
        "```markdown\n# Заголовок\nТекст.\n```",
        "```\nПросто текст\n```",
        "Обычный текст без блоков.",
        "```Неполный блок",
        "Блок в конце```",
        "```json\n{\"key\": \"value\"}\n```",
        "```md Текст```"
    ]
    for test_case in tests_norm:
        print(f"Original: '{test_case}'")
        print(f"Normalized: '{normalize_answer(test_case)}'")

    print(f"Invalid input (int): '{normalize_answer(123)}'") # type: ignore